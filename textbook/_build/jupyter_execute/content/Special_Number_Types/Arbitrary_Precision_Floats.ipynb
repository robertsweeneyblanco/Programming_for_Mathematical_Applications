{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Arbitrary-Precision Floating-Point Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as `BigInt` handles oversized integers, the `BigFloat` type manages floating-point numbers with far more precision than the standard `Float64`.\n",
    "\n",
    "This is essential because `Float64` numbers are stored in binary, and many decimal fractions (like 0.1 or 2.1) cannot be represented perfectly, leading to tiny rounding errors. `BigFloat` allows us to increase the number of bits used for storage, minimizing these errors and enabling high-precision calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The `Float64` Conversion Trap\n",
    "\n",
    "Like with `BigInt`, creating a `BigFloat` using `big()` on a standard number can be tricky. The input number is first interpreted as a `Float64` *before* being converted. If the number can be represented perfectly in binary, the result is what you'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works perfectly because 1.75 is exactly 1 + 1/2 + 1/4,\n",
    "# which has a finite binary representation.\n",
    "big(1.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, if the number cannot be represented exactly as a `Float64`, the initial representation error is carried over and exposed by `BigFloat`'s high precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.100000000000000088817841970012523233890533447265625"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number 2.1 is first rounded to the nearest Float64.\n",
    "# BigFloat then faithfully represents that small inaccuracy with many digits.\n",
    "big(2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The solution, once again, is to use the `big\"...\"` string macro. This tells Julia to parse the decimal string directly into a `BigFloat` at maximum precision, bypassing the `Float64` intermediate step entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.099999999999999999999999999999999999999999999999999999999999999999999999999986"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The string macro correctly parses the decimal \"2.1\" to the highest possible precision.\n",
    "big\"2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Controlling Precision with `setprecision`\n",
    "\n",
    "You can control the precision (the number of **bits** used for the significand) of `BigFloat` calculations using the `setprecision` function. \n",
    "\n",
    "While you can set this globally, the recommended practice is to use a `do` block. This temporarily sets the precision for only the code inside the block, ensuring your high-precision code doesn't have unintended side effects elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333346"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporarily set the precision to 512 bits for the duration of this block.\n",
    "setprecision(512) do\n",
    "    big(1) / big(3)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thanks to multiple dispatch, many of Julia's built-in mathematical functions and constants have specialized methods for `BigFloat`. When you use them, they automatically operate at the currently set precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793238462643383279502884197169399375105820974944592307816406286198"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.096917440979352076742130626395698021050758236508687951179005716992142688513354e-77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# big(pi) computes π to the current BigFloat precision.\n",
    "display(big(pi))\n",
    "\n",
    "# The result of sin(π) should be 0. The tiny non-zero result here is the numerical error\n",
    "# at this high level of precision—still incredibly close to zero!\n",
    "display(sin(big(pi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Visualizing Cubic Convergence with Halley's Method\n",
    "\n",
    "**Halley's method** is a root-finding algorithm that extends Newton's method. It's known for its **cubic convergence**, which means the number of correct digits roughly triples with each iteration. \n",
    "\n",
    "$$ x_{n+1} = x_n - \\frac{2f(x_n) f'(x_n)}{2[f'(x_n)]^2 - f(x_n)f''(x_n)} $$\n",
    "\n",
    "This rapid convergence is often impossible to observe with standard `Float64` because you hit the precision limit almost instantly. But with `BigFloat`, we can use it like a mathematical microscope to watch this phenomenon in action. Let's try to compute $x = \\sqrt[3]{a}$ by finding the root of the equation $f(x) = x^3 - a = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "halley_cuberoot (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: This function is written generically. It will work with Float64, BigFloat,\n",
    "# or any other number type that supports the required arithmetic operations.\n",
    "function halley_cuberoot(a, ε)\n",
    "    # Initial guess is 1, but cast to the same type as the input 'a'.\n",
    "    x = one(a)\n",
    "    \n",
    "    # Initialize the change in x to be larger than the tolerance to ensure the loop runs.\n",
    "    Δx = 2ε\n",
    "    \n",
    "    while Δx ≥ ε\n",
    "        # Apply Halley's formula for f(x) = x^3 - a\n",
    "        # f'(x) = 3x^2, f''(x) = 6x\n",
    "        fx = x^3 - a\n",
    "        f_prime_x = 3x^2\n",
    "        f_double_prime_x = 6x\n",
    "        x_new = x - (2*fx*f_prime_x) / (2*f_prime_x^2 - fx*f_double_prime_x)\n",
    "        \n",
    "        Δx = abs(x_new - x)\n",
    "        x = x_new\n",
    "        \n",
    "        # This print statement is our \"microscope\" to observe the error shrinking.\n",
    "        println(\"Error = \", abs(x - cbrt(a)))\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0.009921049894873164767210607278228350570251464701507980081975112155299676513956221\n",
      "Error = 4.149742382441322899723575934299353308297808730594470544772346647558790369568435e-07\n",
      "Error = 3.001136168965729242876474785354871654493618340778791794290950778604895701742477e-20\n",
      "Error = 1.135217767765559947507625958119369715609728496052297379270293469389407869634748e-59\n",
      "Error = 0.0\n",
      "Error = 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.259921049894873164767210607278228350570251464701507980081975112155299676513956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find the cube root of 2.\n",
    "# By passing in big(2), we trigger the BigFloat methods throughout our function.\n",
    "# The high-precision tolerance (1e-60) is only meaningful because we're using BigFloat.\n",
    "halley_cuberoot(big(2), 1e-60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}