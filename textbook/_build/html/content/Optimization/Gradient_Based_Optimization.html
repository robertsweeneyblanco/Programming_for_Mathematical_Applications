
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>15.1. Gradient-based Optimization &#8212; Programming for Mathematical Applications</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://robertsweeneyblanco.github.io/Programming_for_Mathematical_Applications/content/Optimization/Gradient_Based_Optimization.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="15.2. The Optim package" href="Optim_Package.html" />
    <link rel="prev" title="15. Optimization" href="Chapter_Intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Programming for Mathematical Applications</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   Programming for Mathematical Applications
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Introduction/Chapter_Intro.html">
   1. Introduction to Julia
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Julia_As_A_Calculator.html">
     1.1. Julia as a Calculator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Variables_And_Assignments.html">
     1.2. Variables and Assignments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Functions.html">
     1.3. Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/For_Loops.html">
     1.4. For-Loops
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Conditionals.html">
     1.5. Conditionals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/While_Loops.html">
     1.6. While-Loops
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Introduction/Function_Arguments.html">
     1.7. Function Arguments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Arrays_and_Dictionaries/Chapter_Intro.html">
   2. Arrays and Dictionaries
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Arrays_and_Dictionaries/Introduction_To_Arrays.html">
     2.1. Introduction to Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Arrays_and_Dictionaries/Multi_Dimensional_Arrays.html">
     2.2. Multi-dimensional Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Arrays_and_Dictionaries/Dictionaries.html">
     2.3. Dictionaries
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Plotting/Plotting.html">
   3. Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Debugging/Debugging.html">
   4. Debugging
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Random_Numbers/Chapter_Intro.html">
   5. Random Numbers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Random_Numbers/Distributions.html">
     5.1. Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Random_Numbers/Histograms.html">
     5.2. Histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Random_Numbers/Monte_Carlo.html">
     5.3. Monte Carlo
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Vectorization/Chapter_Intro.html">
   6. Vectorization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Vectorization/Constructing_Arrays.html">
     6.1. Constructing Arrays
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Vectorization/Array_Functions.html">
     6.2. Array Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Vectorization/Logical_Indexing.html">
     6.3. Logical Indexing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Data_Types/Chapter_Intro.html">
   7. Data Types
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data_Types/Arbitrary_Precision_Integers.html">
     7.1. Arbitrary Precision Integers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data_Types/Arbitrary_Precision_Floats.html">
     7.2. Arbitrary Precision Floats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data_Types/Complex_Numbers.html">
     7.3. Complex Numbers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data_Types/Rational_Numbers.html">
     7.4. Rational Numbers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Data_Types/Data_Types_of_Arrays.html">
     7.5. Data Types of Arrays
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Recursion/Recursion.html">
   8. Recursion
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Linear_Algebra/Chapter_Intro.html">
   9. Linear Algebra
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Linear_Algebra/Matrix_Operations.html">
     9.1. Matrix Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Linear_Algebra/Special_Matrices.html">
     9.2. Special Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Linear_Algebra/Linear_Systems_And_Regression.html">
     9.3. Linear Systems and Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Strings_and_File_Processing/Chapter_Intro.html">
   10. Strings and File Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Strings_and_File_Processing/String_Basics.html">
     10.1. String Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Strings_and_File_Processing/String_Functions.html">
     10.2. String Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Strings_and_File_Processing/File_Processing.html">
     10.3. File Processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Structs_And_Objects/Structs_And_Objects.html">
   11. Structs and Objects
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Computational_Geometry/Chapter_Intro.html">
   12. Computational Geometry
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Computational_Geometry/Convex_Hull.html">
     12.1. Convex Hull
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Computational_Geometry/Line_Segment_Interactions.html">
     12.2. Line-segment Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Computational_Geometry/Triangulations.html">
     12.3. Triangulations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Image_Processing/Chapter_Intro.html">
   13. Image Processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Image_Processing/Reading_And_Plotting_Images.html">
     13.1. Reading and Plotting Images
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Image_Processing/Image_Scaling.html">
     13.2. Image Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Image_Processing/Filtering.html">
     13.3. Filtering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Image_Processing/Fourier_Transform.html">
     13.4. Fourier Transform
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Differential_Equations/Chapter_Intro.html">
   14. Differential Equations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Differential_Equations/Initial_Value_Problems.html">
     14.1. Initial Value Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Differential_Equations/Higher_Order_Derivatives_Systems_Of_ODEs.html">
     14.2. Higher Order Derivatives and Systems of ODEs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Differential_Equations/Boundary_Value_Problems.html">
     14.3. Boundary Value Problems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Differential_Equations/DifferentialEquations_Package.html">
     14.4. DifferentialEquations Package
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Chapter_Intro.html">
   15. Optimization
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     15.1. Gradient Based Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Optim_Package.html">
     15.2. Optim Package
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Graphs/Chapter_Intro.html">
   16. Graphs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Graphs/Graph_Basics.html">
     16.1. Graph Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Graphs/Graph_Algorithms.html">
     16.2. Graph Algorithms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Sparse_Matrices/Chapter_Intro.html">
   17. Sparse Matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Sparse_Matrices/Matrix_Designs.html">
     17.1. Matrix Designs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Sparse_Matrices/Sparse_Matrices_In_Julia.html">
     17.2. Sparse Matrices in Julia
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Sparse_Matrices/Application_Graphs.html">
     17.3. Application; Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Sparse_Matrices/Application_Google_Page_Rank.html">
     17.4. Application; Google Page Rank
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/Optimization/Gradient_Based_Optimization.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/robertsweeneyblanco/Programming_for_Mathematical_Applications"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/robertsweeneyblanco/Programming_for_Mathematical_Applications/issues/new?title=Issue%20on%20page%20%2Fcontent/Optimization/Gradient_Based_Optimization.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        <a class="jupyterhub-button" href="https://julia.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/robertsweeneyblanco/Programming_for_Mathematical_Applications&urlpath=tree/Programming_for_Mathematical_Applications/textbook/content/Optimization/Gradient_Based_Optimization.ipynb&branch=main"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-function">
   15.1.1. Gradient function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   15.1.2. Gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#line-searches">
     15.1.2.1. Line searches
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-gradients">
     15.1.2.2. Numerical gradients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#newton-s-method">
   15.1.3. Newton’s method
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Gradient-based Optimization</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-function">
   15.1.1. Gradient function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   15.1.2. Gradient descent
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#line-searches">
     15.1.2.1. Line searches
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#numerical-gradients">
     15.1.2.2. Numerical gradients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#newton-s-method">
   15.1.3. Newton’s method
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="gradient-based-optimization">
<h1><span class="section-number">15.1. </span>Gradient-based Optimization<a class="headerlink" href="#gradient-based-optimization" title="Permalink to this headline">¶</a></h1>
<p>While there are so-called zeroth-order methods which can optimize a function without the gradient,
most applications use first-order method which require the gradient. We will also show an example
of a second-order method, Newton’s method, which require the Hessian matrix (that is, second derivatives).</p>
<p>In our examples, we will optimize the following function of the vector <span class="math notranslate nohighlight">\(x\)</span> with two components:</p>
<div class="math notranslate nohighlight">
\[
f(x) = -\sin\left(\frac{x_1^2}{2} - \frac{x_2^2}{4} + 3 \right) \cos\left(2x_1 + 1 -e^{x_2}\right)
\]</div>
<p>Since <span class="math notranslate nohighlight">\(f\)</span> only depends on two degrees of freedom, we can easily visualize it in the plane.
Below we define the function in Julia, and create a helper function to plot a 2D function using contours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">PyPlot</span>

<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="o">-</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

<span class="k">function</span> <span class="n">fplot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">])</span> <span class="k">for</span> <span class="n">y</span> <span class="k">in</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="k">in</span> <span class="n">x</span><span class="p">]</span>
    
    <span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">contour</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s">&quot;k&quot;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">contourf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
    <span class="n">axis</span><span class="p">(</span><span class="s">&quot;equal&quot;</span><span class="p">)</span>
    <span class="n">colorbar</span><span class="p">()</span>
    <span class="k">return</span>
<span class="k">end</span>

<span class="n">fplot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Gradient_Based_Optimization_1_0.png" src="../../_images/Gradient_Based_Optimization_1_0.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>┌ Warning: `vendor()` is deprecated, use `BLAS.get_config()` and inspect the output instead
│   caller = npyinitialize() at numpy.jl:67
└ @ PyCall /home/mfranco/.julia/packages/PyCall/L0fLP/src/numpy.jl:67
</pre></div>
</div>
</div>
</div>
<p>Note that although the function is only two-dimensional, it is fairly complex with strong nonlinearities and multiple local extrema.</p>
<section id="gradient-function">
<h2><span class="section-number">15.1.1. </span>Gradient function<a class="headerlink" href="#gradient-function" title="Permalink to this headline">¶</a></h2>
<p>Since our methods will be gradient based, we also need to differentiate <span class="math notranslate nohighlight">\(f(x)\)</span>
to produce the gradient <span class="math notranslate nohighlight">\(\nabla f(x)\)</span>. Since this can be difficult to obtain,
or at least highly time consuming, later we will explore alternatives to this
such as numerical differentiation and automatic (symbolic) differentiation.
But to begin with it is convenient to have a function for the gradient, which we
define below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="o">/</span><span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="mi">2</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">cos</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span><span class="o">*</span><span class="n">cos</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">sin</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span><span class="o">*</span><span class="n">sin</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">b1</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b2</span><span class="p">,</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">b1</span> <span class="o">+</span> <span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">*</span><span class="n">b2</span><span class="p">]</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>df (generic function with 1 method)
</pre></div>
</div>
</div>
</div>
</section>
<section id="gradient-descent">
<h2><span class="section-number">15.1.2. </span>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h2>
<p>The <em>gradient descent method</em>, or <em>steepest descent</em>, is based on the observation that for any
given value of <span class="math notranslate nohighlight">\(x\)</span>, the negative gradient <span class="math notranslate nohighlight">\(-\nabla f(x)\)</span> gives the direction of the fastest
decrease of <span class="math notranslate nohighlight">\(f(x)\)</span>. This means that there should be a scalar <span class="math notranslate nohighlight">\(\alpha\)</span> such that</p>
<div class="math notranslate nohighlight">
\[
f(x - \alpha\nabla f(x)) &lt; f(x)
\]</div>
<p>Assuming such an <span class="math notranslate nohighlight">\(\alpha\)</span> can be found, the method then simply starts at some <em>initial guess</em> <span class="math notranslate nohighlight">\(x_0\)</span>
and iterates</p>
<div class="math notranslate nohighlight">
\[
x_{k+1} = x_k - \alpha_k \nabla f(x_k)
\]</div>
<p>until some appropriate termination criterion is satisfied. With some assumptions, the method can be
shown to converge to a local minimum.</p>
<p>In our first implementation below, we simply set <span class="math notranslate nohighlight">\(\alpha_k\)</span> to a specified constant.
We also use <span class="math notranslate nohighlight">\(\|\nabla f(x)\|_2\)</span> for the termination criterion (which goes to zero at local minima).
In order to study the methods properties, we output all of the steps <span class="math notranslate nohighlight">\(x_k\)</span> in a vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">α</span><span class="o">=</span><span class="mf">0.1</span><span class="p">;</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">maxiter</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">gradient</span><span class="o">.^</span><span class="mi">2</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span>
            <span class="k">break</span>
        <span class="k">end</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">α</span><span class="o">*</span><span class="n">gradient</span>
        <span class="n">push!</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">xs</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gradient_descent (generic function with 2 methods)
</pre></div>
</div>
</div>
</div>
<p>We can now run the method on our test problem. We first define a helper function to plot the
“path” of the gradient descent method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">plot_path</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">first</span><span class="o">.</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">last</span><span class="o">.</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="s">&quot;w.&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">first</span><span class="o">.</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="n">last</span><span class="o">.</span><span class="p">(</span><span class="n">xs</span><span class="p">),</span> <span class="s">&quot;r&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>plot_path (generic function with 1 method)
</pre></div>
</div>
</div>
</div>
<p>Next we define three initial guesses <span class="math notranslate nohighlight">\(x_0\)</span>, which are close to different local minima:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">x0s</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.2</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5</span><span class="p">]];</span>
</pre></div>
</div>
</div>
</div>
<p>Finally we run the code for each <span class="math notranslate nohighlight">\(x_0\)</span> and plot the paths. We also output the
length of the paths, and the gradient norm at the final iteration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fplot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">title</span><span class="p">(</span><span class="s">&quot;Gradient descent, fixed </span><span class="se">\$\\</span><span class="s">alpha</span><span class="se">\$</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x0</span> <span class="k">in</span> <span class="n">x0s</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plot_path</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Path length = </span><span class="si">$</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span><span class="s">, ||gradient|| = </span><span class="si">$</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">df</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="o">.^</span><span class="mi">2</span><span class="p">)))</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Gradient_Based_Optimization_13_0.png" src="../../_images/Gradient_Based_Optimization_13_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Path length = 501, ||gradient|| = 1.4715843307921153
Path length = 67, ||gradient|| = 8.918594790414185e-5
Path length = 501, ||gradient|| = 1.757580215668913
</pre></div>
</div>
</div>
</div>
<p>We note that the method can indeed find minima, but suffers from a few problems:</p>
<ul class="simple">
<li><p>The selection of <span class="math notranslate nohighlight">\(\alpha\)</span> is manual and non-obvious. If it is too large, the iterations might
end up too far from the minimum. If it is too small, a large number of iterations are needed.
We will solve this below by introducing so-called <em>line searches</em>.</p></li>
<li><p>The method “zig-zags”, in particular if <span class="math notranslate nohighlight">\(\alpha\)</span> is too large. This is a fundamental problem
with the gradient descent method, and the reason that we will look at better search directions
(such as Newton’s method).</p></li>
</ul>
<section id="line-searches">
<h3><span class="section-number">15.1.2.1. </span>Line searches<a class="headerlink" href="#line-searches" title="Permalink to this headline">¶</a></h3>
<p>One way to improve the gradient descent method is to use a <em>line search</em> to determine
<span class="math notranslate nohighlight">\(\alpha_k\)</span>. The idea is simple: instead of using a fixed <span class="math notranslate nohighlight">\(\alpha_k\)</span>, we minimize
the one-dimensional function <span class="math notranslate nohighlight">\(f(\alpha) = f(x_k - \alpha\nabla f(x_k))\)</span>. This can be
done in many ways, but here we use a simple strategy of successively increasing <span class="math notranslate nohighlight">\(\alpha\)</span>
(by factors of <span class="math notranslate nohighlight">\(2\)</span>) as long as <span class="math notranslate nohighlight">\(f\)</span> decreases.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">line_search</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">direction</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">αmin</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">^</span><span class="mi">20</span><span class="p">,</span> <span class="n">αmax</span><span class="o">=</span><span class="mi">2</span><span class="o">^</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">αmin</span>
    <span class="n">fold</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">while</span> <span class="nb">true</span>
        <span class="k">if</span> <span class="n">α</span> <span class="o">≥</span> <span class="n">αmax</span>
            <span class="k">return</span> <span class="n">α</span>
        <span class="k">end</span>
        <span class="n">fnew</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">α</span><span class="o">*</span><span class="n">direction</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">fnew</span> <span class="o">≥</span> <span class="n">fold</span>
            <span class="k">return</span> <span class="n">α</span><span class="o">/</span><span class="mi">2</span>
        <span class="k">else</span>
            <span class="n">fold</span> <span class="o">=</span> <span class="n">fnew</span>
        <span class="k">end</span>
        <span class="n">α</span> <span class="o">*=</span> <span class="mi">2</span>
    <span class="k">end</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>line_search (generic function with 3 methods)
</pre></div>
</div>
</div>
</div>
<p>Next we write a new gradient descent method which uses line searches instead of
fixed <span class="math notranslate nohighlight">\(\alpha_k\)</span>. It is a very minor change to the previous function and we could
easily have written one general function to handle both these cases, but for
simplicity we create a new function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">gradient_descent_line_search</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">x0</span><span class="p">;</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">maxiter</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">gradient</span><span class="o">.^</span><span class="mi">2</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">tol</span>
            <span class="k">break</span>
        <span class="k">end</span>
        <span class="n">α</span> <span class="o">=</span> <span class="n">line_search</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">-=</span> <span class="n">α</span><span class="o">*</span><span class="n">gradient</span>
        <span class="n">push!</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">xs</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>gradient_descent_line_search (generic function with 1 method)
</pre></div>
</div>
</div>
</div>
<p>Running the same test case as before with this function, we see that it automatically
determines appropriate <span class="math notranslate nohighlight">\(\alpha_k\)</span> values and converge for all three initial guesses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fplot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">title</span><span class="p">(</span><span class="s">&quot;Gradient descent, line searches for </span><span class="se">\$\\</span><span class="s">alpha</span><span class="se">\$</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x0</span> <span class="k">in</span> <span class="n">x0s</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">gradient_descent_line_search</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
    <span class="n">plot_path</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Path length = </span><span class="si">$</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span><span class="s">, ||gradient|| = </span><span class="si">$</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">df</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="o">.^</span><span class="mi">2</span><span class="p">)))</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Gradient_Based_Optimization_20_0.png" src="../../_images/Gradient_Based_Optimization_20_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Path length = 47, ||gradient|| = 7.870693264979224e-5
Path length = 19, ||gradient|| = 2.7076595197618347e-5
Path length = 34, ||gradient|| = 6.996634619625892e-5
</pre></div>
</div>
</div>
</div>
</section>
<section id="numerical-gradients">
<h3><span class="section-number">15.1.2.2. </span>Numerical gradients<a class="headerlink" href="#numerical-gradients" title="Permalink to this headline">¶</a></h3>
<p>An alternative to implementing the gradient function <code class="docutils literal notranslate"><span class="pre">df</span></code> by hand as above, it can
be computed numerically using finite differences:</p>
<div class="math notranslate nohighlight">
\[
\left(\nabla f(x)\right)_k \approx \frac{f(x + \epsilon d^k) - f(x - \epsilon d^k)}{2\epsilon}
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\epsilon\)</span> is a (small) step size parameter, and the vector <span class="math notranslate nohighlight">\(d^k\)</span> is defined by <span class="math notranslate nohighlight">\((d^k)_j = \delta_{ij}\)</span>
(that is, a zero vector with a single 1 at position <span class="math notranslate nohighlight">\(k\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">finite_difference_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">ϵ</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">n</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ϵ</span>
        <span class="n">fP</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span><span class="n">ϵ</span>
        <span class="n">fM</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fP</span> <span class="o">-</span> <span class="n">fM</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="n">ϵ</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">df</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finite_difference_gradient (generic function with 2 methods)
</pre></div>
</div>
</div>
</div>
<p>We can now run the previous test case, without having to compute <code class="docutils literal notranslate"><span class="pre">df</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fplot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">title</span><span class="p">(</span><span class="s">&quot;Gradient descent, line searches for </span><span class="se">\$\\</span><span class="s">alpha</span><span class="se">\$</span><span class="s">, numerical gradients&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x0</span> <span class="k">in</span> <span class="n">x0s</span>
    <span class="n">num_df</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">finite_difference_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">gradient_descent_line_search</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">num_df</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
    <span class="n">plot_path</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Path length = </span><span class="si">$</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span><span class="s">, ||gradient|| = </span><span class="si">$</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">df</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="o">.^</span><span class="mi">2</span><span class="p">)))</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Gradient_Based_Optimization_24_0.png" src="../../_images/Gradient_Based_Optimization_24_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Path length = 47, ||gradient|| = 7.870695958738454e-5
Path length = 19, ||gradient|| = 2.7076776490056162e-5
Path length = 34, ||gradient|| = 6.996618216493087e-5
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="newton-s-method">
<h2><span class="section-number">15.1.3. </span>Newton’s method<a class="headerlink" href="#newton-s-method" title="Permalink to this headline">¶</a></h2>
<p>Even with line searches, the gradient descent method still suffers from the zig-zag behavior
and slow convergence. If second derivatives can be obtained, <em>Newton’s method</em> can converge
much faster. A simple way to describe the method is that we change the search direction in
gradient descent to <span class="math notranslate nohighlight">\(H(x_k)^{-1}\nabla f(x_k)\)</span> instead of just <span class="math notranslate nohighlight">\(\nabla f(x_k)\)</span>, where
<span class="math notranslate nohighlight">\(H(x_k)\)</span> is the <em>Hessian matrix</em>.</p>
<p>We compute <span class="math notranslate nohighlight">\(H(x)\)</span> numerically using similar expressions as before (but for second derivatives):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">function</span> <span class="n">finite_difference_hessian</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">ϵ</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ddf</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
    <span class="n">f0</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">n</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ϵ</span>
        <span class="n">fP</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span><span class="n">ϵ</span>
        <span class="n">fM</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">ddf</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fP</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">f0</span> <span class="o">+</span> <span class="n">fM</span><span class="p">)</span> <span class="o">/</span> <span class="n">ϵ</span><span class="o">^</span><span class="mi">2</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">n</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">:</span><span class="n">n</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ϵ</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">ϵ</span>
        <span class="n">fPP</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span><span class="n">ϵ</span>
        <span class="n">fMP</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span><span class="n">ϵ</span>
        <span class="n">fMM</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">2</span><span class="n">ϵ</span>
        <span class="n">fPM</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="n">ddf</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fPP</span> <span class="o">-</span> <span class="n">fMP</span> <span class="o">-</span> <span class="n">fPM</span> <span class="o">+</span> <span class="n">fMM</span><span class="p">)</span> <span class="o">/</span> <span class="mi">4</span><span class="n">ϵ</span><span class="o">^</span><span class="mi">2</span>
        <span class="n">ddf</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">ddf</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">ddf</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finite_difference_hessian (generic function with 2 methods)
</pre></div>
</div>
</div>
</div>
<p>We implement Newton’s method by re-using our gradient descent method with a different gradient direction.</p>
<p>Newton’s method is more sensitive to the initial guess <span class="math notranslate nohighlight">\(x_0\)</span>, and in order to converge we have to move
two of our values closer to their minima. However, when the method converges it is very fast.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fplot</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">title</span><span class="p">(</span><span class="s">&quot;Newton&#39;s method, line searches for </span><span class="se">\$\\</span><span class="s">alpha</span><span class="se">\$</span><span class="s">, numerical gradients and Hessians&quot;</span><span class="p">)</span>
<span class="n">x0s</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]];</span>
<span class="k">for</span> <span class="n">x0</span> <span class="k">in</span> <span class="n">x0s</span>
    <span class="n">search_dir</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">finite_difference_hessian</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">x</span><span class="p">)</span> <span class="o">\</span> <span class="n">finite_difference_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">gradient_descent_line_search</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">search_dir</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
    <span class="n">plot_path</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Path length = </span><span class="si">$</span><span class="p">(</span><span class="n">length</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span><span class="s">, ||gradient|| = </span><span class="si">$</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="n">df</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="k">end</span><span class="p">])</span><span class="o">.^</span><span class="mi">2</span><span class="p">)))</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Gradient_Based_Optimization_28_0.png" src="../../_images/Gradient_Based_Optimization_28_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Path length = 5, ||gradient|| = 2.459525335329783e-6
Path length = 4, ||gradient|| = 1.222661468371642e-5
Path length = 6, ||gradient|| = 1.7631665079368057e-8
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.7"
        },
        kernelOptions: {
            kernelName: "julia-1.7",
            path: "./content/Optimization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.7'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Chapter_Intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">15. </span>Optimization</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Optim_Package.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15.2. </span>The <code class="docutils literal notranslate"><span class="pre">Optim</span></code> package</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Per-Olof Persson, Michael Franco, and Robert Sweeney Blanco<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>