{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Floating-Point Arithmetic\n",
    "\n",
    "Modern computers perform calculations with incredible speed, but they do so with finite resources. This appendix explores how computers represent integers and real numbers using a fixed number of binary digits (bits). Understanding this foundation is crucial for anyone doing numerical work, as it explains many common sources of error and surprising behavior in scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Computers Represent Integers\n",
    "\n",
    "At the lowest level, all data in a computer is stored in **binary**, a base-2 number system using only the digits 0 and 1. For example, the binary number $1011001_2$ corresponds to the decimal number:\n",
    "\n",
    "$$ \\begin{align*} 1011001_2 &= 1\\cdot 2^6 + 0\\cdot 2^5 + 1\\cdot 2^4 + 1\\cdot 2^3 + 0\\cdot 2^2 + 0\\cdot 2^1 + 1 \\cdot 2^0 \\\\ &= 64 + 0 + 16 + 8 + 0 + 0 + 1 \\\\ &= 89_{10} \\end{align*} $$\n",
    "\n",
    "In Julia, you can specify a number in binary using the `0b` prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The `0b` prefix tells Julia to interpret the number as binary.\n",
    "Int(0b1011001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsigned Integers\n",
    "Unsigned integers (like Julia's `UInt8`, `UInt16`, etc.) use all their bits to represent the magnitude of a positive number. We can view the raw binary representation using the `bitstring` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"01011001\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A UInt8 uses 8 bits. The number 89 is padded with a leading zero.\n",
    "bitstring(UInt8(89))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a `UInt64`, which uses 64 bits, the largest possible number is one where all bits are 1. This corresponds to the value $2^{64}-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signed Integers and Two's Complement\n",
    "\n",
    "To represent negative numbers, computers most commonly use the **two's complement** format. In this system, the most significant (leftmost) bit acts as a sign indicator: if it's `0`, the number is positive; if it's `1`, the number is negative.\n",
    "\n",
    "The negative of a number $x$ is defined as the value $y$ such that $x+y = 2^n$ for an $n$-bit integer. For example, with 8 bits, the positive number 89 is `01011001`. Its two's complement is `10100111`, because:\n",
    "\n",
    "$$ 01011001_2 + 10100111_2 = 100000000_2 = 2^8 $$\n",
    "\n",
    "Therefore, the bit pattern `10100111` represents $-89$. A major advantage of this system is that the same hardware can be used for both addition and subtraction.\n",
    "\n",
    "*(A quick way to find the two's complement is to invert all the bits and add one.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"01011001\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The bitstring for a positive Int8. The first bit is 0.\n",
    "bitstring(Int8(89))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"10100111\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The bitstring for a negative Int8. The first bit is 1.\n",
    "bitstring(Int8(-89))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this format, an `Int64` can represent numbers from $-2^{63}$ to $2^{63}-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " -9223372036854775808  9223372036854775807\n",
       " -9223372036854775808  9223372036854775807"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the minimum and maximum values for a 64-bit signed integer.\n",
    "[typemin(Int64) typemax(Int64); -2^63 2^63-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed-Point Numbers\n",
    "\n",
    "One way to represent fractional numbers is to fix the position of the binary point. For example:\n",
    "$$ 101.1011_2 = 2^2 + 2^0 + 2^{-1} + 2^{-3} + 2^{-4} = 5.6875_{10} $$\n",
    "While simple, this **fixed-point** representation has a major drawback for scientific use: it can't efficiently represent both very large and very small numbers simultaneously. To solve this, computers use a floating-point representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating-Point Numbers: Precision for Range\n",
    "\n",
    "Floating-point numbers trade a fixed amount of precision for a vastly larger range of representable magnitudes, much like scientific notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy to Scientific Notation\n",
    "\n",
    "Recall that a number in scientific notation has three parts:\n",
    "\n",
    "$$ {\\LARGE \\underbrace{-}_{\\text{sign}} \\underbrace{1.602}_{\\text{significand}} \\times \\underbrace{10}_{\\text{base}} \\!^{\\underbrace{-19}_{\\text{exponent}}} } $$\n",
    "\n",
    "\n",
    "Floating point numbers are represented in a similar way, as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\pm \\left( d_0 + d_1\\beta^{-1} + \\ldots + d_{p-1} \\beta^{-(p-1)} \\right)\n",
    " \\beta^e,\\quad 0\\le d_i<\\beta\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "with *base* $\\beta$ and *precision* $p$. The number is *normalized*\n",
    "if $d_0\\ne0$ (use a special case to represent $0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Floating-Point Numbers\n",
    "\n",
    "This representation has some non-intuitive consequences:\n",
    "- **Uneven Spacing**: The gaps between representable numbers are not uniform. They are smallest near zero and grow larger as the magnitude of the numbers increases.\n",
    "- **Relative Error**: For any real number $x$, there's a nearby floating-point number $x'$ such that the error relative to $x$ is small: $|x-x'| \\le \\epsilon_\\mathrm{machine} |x|$. This $\\epsilon_\\mathrm{machine}$ is a fundamental constant for a given floating-point type.\n",
    "\n",
    "For example, the number line below shows all the representable numbers for the case $\\beta=2, p=3, e_\\mathrm{min}=-1, e_\\mathrm{max}=2$.\n",
    "\n",
    "![floating_point_number_line](floating_point_number_line.png \"Floating Point Number Line\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The IEEE 754 Standard\n",
    "Modern computers follow the **IEEE 754 standard** for floating-point arithmetic. This standard defines the layout of the bits, how to handle special values, and the rules for rounding.\n",
    "\n",
    "A standard **single-precision** number (`Float32` in Julia) uses 32 bits, allocated as:\n",
    "- 1 **sign bit** (S): `0` for positive, `1` for negative.\n",
    "- 8 **exponent bits** (E): Stores the exponent in a biased format.\n",
    "- 23 **significand bits** (M, also called the mantissa): Stores the fractional part of the number.\n",
    "\n",
    "$$ \\begin{array}{c|c|c} \\text{S (1 bit)} & \\text{E (8 bits)} & \\text{M (23 bits)} \\\\ \\hline \\mathtt{x} & \\mathtt{xxxxxxxx} & \\mathtt{xxxxxxxxxxxxxxxxxxxxxxx} \\end{array} $$\n",
    "\n",
    "The value of a normalized number is given by:\n",
    "$$ {\\Large (-1)^S \\times (1.M)_2 \\times 2^{E-127} } $$\n",
    "\n",
    "Notice the `1.` in `(1.M)`. This is a clever optimization: since the first digit of a normalized binary number is always 1, it doesn't need to be stored. This is called the **hidden bit** and it gives us an extra bit of precision for free!\n",
    "\n",
    "The standard also defines bit patterns for **special quantities**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{array}{c|c|c|c} & E=0 & 0<E<255 & E=255 \\\\ \\hline M=0 & \\pm0 & \\text{Normalized numbers} & \\pm\\infty \\\\ \\hline M\\ne0 & \\text{Denormalized numbers} & \\text{Normalized numbers} & \\text{NaN} \\end{array} $$\n",
    "\n",
    "**Double precision** (`Float64` in Julia) works the same way but uses 64 bits total (1 sign, 11 exponent, 52 significand), offering much greater precision and range.\n",
    "\n",
    "$$ \\begin{array}{l|l|l} & \\text{Single Precision (Float32)} & \\text{Double Precision (Float64)} \\\\ \\hline \\text{Significand Precision} & \\text{24 bits (23 stored)} & \\text{53 bits (52 stored)} \\\\ \\hline \\text{Exponent Size} & \\text{8 bits} & \\text{11 bits} \\\\ \\hline \\text{Range of Magnitudes} & \\approx 10^{-38} \\text{ to } 10^{38} & \\approx 10^{-308} \\text{ to } 10^{308} \\\\ \\hline \\epsilon_\\mathrm{machine} & 2^{-24}\\approx 6 \\times 10^{-8} & 2^{-53} \\approx 1.1 \\times 10^{-16} \\end{array} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating-Point Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Floating-Point Numbers\n",
    "\n",
    "Because of tiny representation errors, you should **never use `==` to check if two floating-point numbers are equal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mathematically, this should be exactly 5/3.\n",
    "x = (1 - 2/3) * 5\n",
    "\n",
    "# But due to small binary representation errors, it's not.\n",
    "x == 5/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, check if the numbers are \"close enough\" by testing if their absolute difference is smaller than a small tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The error is tiny, but non-zero.\n",
    "abs(x - 5/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia provides the function `isapprox` (and the convenient operator `≈`, typed `\\approx` + Tab) which does this correctly by checking both relative and absolute tolerances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the correct way to compare floats for approximate equality.\n",
    "x ≈ 5/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overflow and Underflow\n",
    "\n",
    "**Overflow** occurs when a calculation results in a number larger than the maximum representable value, which becomes `Inf` (infinity). **Underflow** occurs when a number is too small (too close to zero) to be represented, which becomes `0.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0e308"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The largest representable Float64 is around 1e308.\n",
    "1e308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplying it by 2 causes an overflow.\n",
    "2 * 1e308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0e-308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The smallest positive normalized Float64 is around 1e-308.\n",
    "1e-308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0e-324"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing this by 2^52 causes an underflow.\n",
    "smallest = 1e-308\n",
    "smallest / 2^51 # Still representable as a denormalized number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest / 2^52 # Too small, underflows to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catastrophic Cancellation\n",
    "\n",
    "Subtracting two nearly-equal numbers can cause a massive loss of relative precision. The leading, most significant digits cancel out, leaving only the noisy, least significant digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998420350369826"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two random numbers and their difference.\n",
    "x = rand()\n",
    "y = rand()\n",
    "z = x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.599853515625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a large number to both x and y. They are now nearly equal.\n",
    "x1 = x + 1e12\n",
    "y1 = y + 1e12\n",
    "\n",
    "# Their difference should still be z, but precision is lost during the subtraction.\n",
    "z1 = x1 - y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1480588017365179e-5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new result `z1` differs from the true result `z`.\n",
    "z1 - z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Epsilon\n",
    "\n",
    "**Machine epsilon** is the distance between 1.0 and the next largest representable floating-point number. It defines the smallest relative change that can be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Float64, epsilon is ~2.2e-16. Anything smaller added to 1.0 is lost.\n",
    "eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a number smaller than epsilon has no effect.\n",
    "1.0 + 1e-17 == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can calculate epsilon by finding the smallest power of 2 that `1.0` can resolve.\n",
    "e = 1.0\n",
    "while 1.0 + e > 1.0\n",
    "    e = e / 2\n",
    "end\n",
    "e * 2 # The last successful value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The gap between numbers is relative to their magnitude.\n",
    "# `eps(x)` gives the gap at `x`.\n",
    "eps(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.81474976710656e14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps(2.0^100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Values: ±0, Inf, and NaN\n",
    "The IEEE 754 standard includes several special quantities to handle edge cases gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signed Zeros\n",
    "There are distinct positive (`+0.0`) and negative (`-0.0`) zeros. They compare as equal but can produce different results in some calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0000000000000000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitstring(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1000000000000000000000000000000000000000000000000000000000000000\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitstring(-0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sign of zero can matter!\n",
    "1.0 / 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-Inf"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 / -0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infinity (`Inf`)\n",
    "Infinity is the result of overflow or division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.0^10.0^10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inf"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inf + Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not-a-Number (`NaN`)\n",
    "`NaN` is the result of undefined operations, such as `0/0` or `Inf - Inf`. Any operation involving `NaN` results in `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0 / 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inf - Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN is \"contagious\".\n",
    "NaN + 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unique property of `NaN` is that it is not equal to anything, including itself. Therefore, you must use the `isnan()` function to check for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a defining feature of NaN!\n",
    "NaN == NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `isnan` function to test for NaN.\n",
    "isnan(NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding Behavior\n",
    "\n",
    "IEEE 754 specifies a **round-to-nearest, ties-to-even** rule. If a number is exactly halfway between two representable values, it is rounded to the one whose last bit is zero (the \"even\" one). This avoids the statistical bias of always rounding .5 up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = eps()/2 # This is exactly half the gap after 1.0\n",
    "\n",
    "# `1.0 + e` is halfway between 1.0 and `1.0 + 2e`. It rounds down to 1.0 (even mantissa).\n",
    "1.0 + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `1.0 + 3e` is halfway between `1.0 + 2e` and `1.0 + 4e`.\n",
    "# `1.0 + 2e` has an odd mantissa.\n",
    "# `1.0 + 4e` has an even mantissa, so it rounds up.\n",
    "1.0 + 3*e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple | Result\n",
      "-----------------\n",
      "0        | 0.0\n",
      "1        | 0.0\n",
      "2        | 2.0\n",
      "3        | 4.0\n",
      "4        | 4.0\n",
      "5        | 4.0\n",
      "6        | 6.0\n",
      "7        | 8.0\n",
      "8        | 8.0\n",
      "9        | 8.0\n",
      "10       | 10.0\n"
     ]
    }
   ],
   "source": [
    "# We can see the pattern: 1, 3, 5... round up, while 0, 2, 4... round down.\n",
    "println(\"Multiple | Result\")\n",
    "println(\"-----------------\")\n",
    "for mul in 0:10\n",
    "    result = ((1.0 + mul * e) - 1.0) / e\n",
    "    println(rpad(mul, 8), \" | \", result)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Bit-Level Representations\n",
    "This helper function lets us inspect the bit patterns of `Float32` numbers to see these rules in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Special Values ---\n",
      "           0 = 0 00000000 00000000000000000000000\n",
      "           0 = 0 00000000 00000000000000000000000\n",
      "         Inf = 0 11111111 00000000000000000000000\n",
      "        -Inf = 1 11111111 00000000000000000000000\n",
      "         NaN = 0 11111111 10000000000000000000000\n",
      "\n",
      "--- Integers ---\n",
      "           1 = 0 01111111 00000000000000000000000\n",
      "           2 = 0 10000000 00000000000000000000000\n",
      "           3 = 0 10000000 10000000000000000000000\n",
      "           4 = 0 10000001 00000000000000000000000\n",
      "           5 = 0 10000001 01000000000000000000000\n",
      "\n",
      "--- Numbers Just Above 1.0 ---\n",
      "           1 = 0 01111111 00000000000000000000000\n",
      "   1.0000001 = 0 01111111 00000000000000000000001\n",
      "   1.0000002 = 0 01111111 00000000000000000000010\n",
      "   1.0000004 = 0 01111111 00000000000000000000011\n",
      "   1.0000005 = 0 01111111 00000000000000000000100\n",
      "   1.0000006 = 0 01111111 00000000000000000000101\n"
     ]
    }
   ],
   "source": [
    "using Printf\n",
    "\n",
    "# A helper function to format a 32-bit string into Sign | Exponent | Mantissa.\n",
    "split32(s) = s[1] * \" \" * s[2:9] * \" \" * s[10:32]\n",
    "\n",
    "# A function to print a number and its Float32 bit pattern.\n",
    "showbits(x) = @printf(\"%12.8g = %s\\n\", x, split32(bitstring(Float32(x))))\n",
    "\n",
    "println(\"--- Special Values ---\")\n",
    "showbits.([0, -0, Inf, -Inf, NaN]);\n",
    "\n",
    "println(\"\\n--- Integers ---\")\n",
    "showbits.(1:5);\n",
    "\n",
    "println(\"\\n--- Numbers Just Above 1.0 ---\")\n",
    "showbits.(1 .+ (0:5).*2^-23);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
